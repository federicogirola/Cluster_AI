parameters_k = np.arange(20,31,5)
# Ahora cambiamos el estimador, usaremos Kneighbors Regressor

n_folds = 5
# Lista del parametro lambda (parametro 'alpha')
parameters = {'n_neighbors': parameters_k}
# Definimos nuevamente el objeto GS con los parametros previamente definidos
gs = GridSearchCV(neighbors.KNeighborsRegressor(), param_grid=parameters,refit=True,
                  cv=n_folds, scoring="neg_mean_squared_error",
                  verbose=3)
# Entrenamos
gs.fit(xtrain_scal, ytrain)
print(gs.best_estimator_, "\n")
print(gs.best_params_, "\n")
print(gs.best_score_, "\n")
# Prediccion + Metricas
knr_prediction = gs.best_estimator_.predict(xtest_scal)
knr_r2 = r2_score(y_true=ytest, y_pred=knr_prediction)
knr_mse = mean_squared_error(y_true=ytest, y_pred=knr_prediction)
knr_mae = mean_absolute_error(y_true=ytest, y_pred=knr_prediction)
plt.scatter(knr_prediction, ytest)
plt.plot(np.arange(0,100),np.arange(0,100), 'r', label='Identity')
plt.xlabel('Predictions')
plt.ylabel('True Values')
plt.legend()
print(f'R2 score: {knr_r2:.6f}')
print(f'MAE: {knr_mse:.6f}')
print(f'MSE: {knr_mae:.6f}')
